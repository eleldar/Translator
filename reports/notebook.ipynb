{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e5f5f6",
   "metadata": {},
   "source": [
    "# Характеристики моделей с сайта https://huggingface.co/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d60c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm as tn\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "fbdc1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements_to_notebook.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5166e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad054b900f074e3f96cf5575e8dbd921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_models():\n",
    "    '''Доступные модели на сайте huggingface'''\n",
    "    cite = 'https://huggingface.co'\n",
    "    url = \"https://huggingface.co/Helsinki-NLP\"\n",
    "    url_data = requests.get(url)\n",
    "    url_tree = BeautifulSoup(url_data.content, 'html.parser')\n",
    "    data = url_tree.find_all('article', {\n",
    "        'class': 'overview-card-wrapper group'\n",
    "    })\n",
    "    result = []\n",
    "    for item in tn(data):\n",
    "        href = item.find('a', {'class':\"block p-2\"}).get('href')\n",
    "        model = requests.get(cite + href)    \n",
    "        model_tree = BeautifulSoup(model.content, 'html.parser')\n",
    "        result.append(model_tree)\n",
    "    return tuple(result)\n",
    "\n",
    "\n",
    "source = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d501b50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "6550e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_from_github(md):\n",
    "    '''Новейший релиз и размер из github'''\n",
    "    md_data = requests.get(md)\n",
    "    md_tree = BeautifulSoup(md_data.content, 'html.parser')\n",
    "    data = md_tree.find('article', {\n",
    "        'class': 'markdown-body entry-content container-lg'\n",
    "    })\n",
    "    try:   \n",
    "        data = [i for i in data.find_all('li') if 'download:' in str(i)]\n",
    "    except AttributeError:\n",
    "        file = urlopen(md)        \n",
    "        text = \"\".join([line.decode(\"utf-8\") for line in file])\n",
    "        text = [i for i in text.split('# opus') if i]\n",
    "        text = [i.split('\\n') for i in text]\n",
    "        dl = []\n",
    "        for i in text:\n",
    "            tmp = []\n",
    "            for j in i:\n",
    "                if 'http' in j:\n",
    "                    tmp.append(j)\n",
    "            dl.append(tmp)\n",
    "        urls = {}\n",
    "        for i in dl:            \n",
    "            for j in i:\n",
    "                if '.zip' in j:\n",
    "                    url = 'http' + j.split('http')[-1][:-1]\n",
    "                    date = \"-\".join(url.split('.zip')[0].split('-')[-3:][::-1])\n",
    "                    date = datetime.strptime(date, '%d-%m-%Y').date()\n",
    "                    urls[date] = i\n",
    "                    break\n",
    "        link_lst = urls[max(urls)]\n",
    "        link = [i for i in link_lst if '.zip' in i][0]\n",
    "        link = 'http' + link.split('http')[-1][:-1]\n",
    "        site = urlopen(link)\n",
    "        meta = site.info()\n",
    "        size = round(int(meta.values()[0]) / 2 ** 20, 2)\n",
    "        test = [i for i in link_lst if '.test.' in i][0]\n",
    "        test = 'http' + test.split('http')[-1][:-1]\n",
    "        return size, link, test    \n",
    "    urls = {}\n",
    "    for dt in data:\n",
    "        try:\n",
    "            url = dt.find('a').get('href')\n",
    "            date = \"-\".join(url.split('.zip')[0].split('-')[-3:][::-1])\n",
    "            date = datetime.strptime(date, '%d-%m-%Y').date()\n",
    "            urls[date] = url\n",
    "        except:\n",
    "            continue\n",
    "    if urls:\n",
    "        while urls:\n",
    "            try:\n",
    "                link = urls[max(urls)]\n",
    "                site = urlopen(link)\n",
    "                meta = site.info()\n",
    "                size = round(int(meta.values()[0]) / 2 ** 20, 2)\n",
    "                return size, link\n",
    "            except:\n",
    "                del urls[max(urls)]            \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d63cf835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c631e94e7d0641fb9b4e9619563ec803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно обработано страниц: 1339\n",
      "Необработано страниц: 1\n"
     ]
    }
   ],
   "source": [
    "def get_data_dicts(source):\n",
    "    \"\"\"Метаданные о каждой модели\"\"\"\n",
    "    result, error = [], []\n",
    "    for model_tree in tn(source):  \n",
    "        records = model_tree.find('div', \n",
    "                                  {'prose dark:prose-light'}\n",
    "                                 ).find_all('ul')\n",
    "        scores = model_tree.find('div', {'max-w-full overflow-auto'})\n",
    "        notions = records[0] if records else 0\n",
    "        dct = {}\n",
    "        if notions and scores:\n",
    "            rows = notions.find_all('li') \n",
    "            key_scores = scores.find_all('thead')\n",
    "            val_scores = scores.find_all('tbody')\n",
    "            size_url = None\n",
    "            for row in rows:\n",
    "                column = row.find('p') if row.find_all('p') else row                \n",
    "                if column and ': ' in column.text:\n",
    "                    key, value = list(map(str.strip, \n",
    "                                          column.text.split(\": \")))[:2]\n",
    "                    if column.find('a'):                        \n",
    "                        href = column.find('a').get('href')\n",
    "                        if href.strip()[-3:] == '.md':\n",
    "                            size_url = get_size_from_github(href)\n",
    "                            dct[key] = href\n",
    "                            dct['download original weights'] = size_url[1]\n",
    "                            if size_url[1]:\n",
    "                                date = size_url[1].split('.zip')[0]\\\n",
    "                                    .split('-')[-3:][::-1]                                    \n",
    "                                dct['date'] = '.'.join(date)\n",
    "                                dct['size (Mb)'] = size_url[0]                            \n",
    "                            else:\n",
    "                                dct['date'] = None\n",
    "                                dct['size (Mb)'] = None\n",
    "                        elif href.strip()[-4:] == '.txt':\n",
    "                            dct[key] = href\n",
    "                    elif key != 'download original weights':\n",
    "                        dct[key] = value\n",
    "                else:\n",
    "                    if \"comment\" in dct:\n",
    "                        dct[\"comment\"] += \", \" + str(column)\n",
    "                    else:\n",
    "                        dct[\"comment\"] = str(column)\n",
    "            if len(size_url) == 3:                \n",
    "                dct['test set translations'] = size_url[2]\n",
    "            dct[\"scores\"] = []\n",
    "            if key_scores and val_scores:\n",
    "                ks, vs = key_scores[0].text.split(), val_scores[0].text.split()\n",
    "                for k, v in zip(ks, vs):\n",
    "                    if k == 'BLEU' or k == 'chr-F':\n",
    "                        dct[\"scores\"].append(f'{k}: {v}')\n",
    "            if not dct[\"scores\"]:\n",
    "                records = model_tree.find('div', \n",
    "                                          {'prose dark:prose-light'}\n",
    "                                         ).find_all('ul')\n",
    "                scores = []\n",
    "                for record in records[0].find_all('li'):\n",
    "                    if 'BLEU' in record.text or 'chr-F' in record.text:\n",
    "                        scores.append(record)\n",
    "                local_score = {}\n",
    "                for score in scores:\n",
    "                    string = [s for s in score.text.split('\\n') if s]\n",
    "                    local_score[string[0]] = [\n",
    "                        \": \".join(string[i:i + 2]) \n",
    "                        for i in range(3, len(string[3:]), 2)\n",
    "                    ]\n",
    "                dct[\"scores\"] = local_score\n",
    "            result.append(dct)\n",
    "        else:\n",
    "            error.append(model_tree)\n",
    "    print(f'Успешно обработано страниц: {len(result)}')\n",
    "    print(f'Необработано страниц: {len(error)}')\n",
    "    return result, error\n",
    "\n",
    "\n",
    "data, error = get_data_dicts(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "98ca0ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 1)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "11c285c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# множество столбцов сформированных эмпирическим путем\n",
    "columns = {'source language name', 'pre-processing', 'source group', \n",
    "           'OPUS readme', 'scores', 'model', 'target language name', \n",
    "           'size (Mb)', 'dataset', 'test set translations', \n",
    "           'source languages', 'download original weights', \n",
    "           'source language(s)', 'target group', 'valid language labels', \n",
    "           'date', 'comment', 'test set scores', 'raw target language(s)', \n",
    "           'target language codes', 'source language codes',  \n",
    "           'target language(s)', 'raw source language(s)', 'target languages'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4ce78104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source language name</th>\n",
       "      <th>test set translations</th>\n",
       "      <th>valid language labels</th>\n",
       "      <th>target language codes</th>\n",
       "      <th>raw target language(s)</th>\n",
       "      <th>pre-processing</th>\n",
       "      <th>source group</th>\n",
       "      <th>test set scores</th>\n",
       "      <th>comment</th>\n",
       "      <th>target group</th>\n",
       "      <th>...</th>\n",
       "      <th>target languages</th>\n",
       "      <th>source language(s)</th>\n",
       "      <th>download original weights</th>\n",
       "      <th>scores</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>target language name</th>\n",
       "      <th>target language(s)</th>\n",
       "      <th>source languages</th>\n",
       "      <th>raw source language(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ita</td>\n",
       "      <td>normalization + SentencePiece (spm32k,spm32k)</td>\n",
       "      <td>French</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>None</td>\n",
       "      <td>Italian</td>\n",
       "      <td>...</td>\n",
       "      <td>ita</td>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>[BLEU: 54.8, chr-F: 0.737]</td>\n",
       "      <td>transformer-align</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fra</td>\n",
       "      <td>fra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>&gt;&gt;mol&lt;&lt; &gt;&gt;ron&lt;&lt;</td>\n",
       "      <td>None</td>\n",
       "      <td>mol ron</td>\n",
       "      <td>normalization + SentencePiece (spm32k,spm32k)</td>\n",
       "      <td>German</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>&lt;p&gt;a sentence initial language token is requir...</td>\n",
       "      <td>Romanian</td>\n",
       "      <td>...</td>\n",
       "      <td>mol ron</td>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>[BLEU: 42.0, chr-F: 0.636]</td>\n",
       "      <td>transformer-align</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>deu</td>\n",
       "      <td>deu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>normalization + SentencePiece (spm32k,spm32k)</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "      <td>...</td>\n",
       "      <td>eng</td>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>[BLEU: 27.1, chr-F: 0.550]</td>\n",
       "      <td>transformer-align</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>normalization + SentencePiece (spm32k,spm32k)</td>\n",
       "      <td>English</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>&lt;p&gt;a sentence initial language token is requir...</td>\n",
       "      <td>Romanian</td>\n",
       "      <td>...</td>\n",
       "      <td>mol ron</td>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>[BLEU: 33.5, chr-F: 0.610]</td>\n",
       "      <td>transformer-align</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>eng</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>normalization + SentencePiece (spm32k,spm32k)</td>\n",
       "      <td>English</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>None</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>...</td>\n",
       "      <td>jpn</td>\n",
       "      <td>None</td>\n",
       "      <td>https://object.pouta.csc.fi/Tatoeba-MT-models/...</td>\n",
       "      <td>[BLEU: 15.2, chr-F: 0.258]</td>\n",
       "      <td>transformer-align</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>eng</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  source language name                              test set translations  \\\n",
       "0                 None  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "1                 None  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "2                 None  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "3                 None  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "4                 None  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "\n",
       "  valid language labels target language codes raw target language(s)  \\\n",
       "0                  None                  None                    ita   \n",
       "1       >>mol<< >>ron<<                  None                mol ron   \n",
       "2                  None                  None                   None   \n",
       "3                                        None                   None   \n",
       "4                  None                  None                   None   \n",
       "\n",
       "                                  pre-processing source group  \\\n",
       "0  normalization + SentencePiece (spm32k,spm32k)       French   \n",
       "1  normalization + SentencePiece (spm32k,spm32k)       German   \n",
       "2  normalization + SentencePiece (spm32k,spm32k)      Finnish   \n",
       "3  normalization + SentencePiece (spm32k,spm32k)      English   \n",
       "4  normalization + SentencePiece (spm32k,spm32k)      English   \n",
       "\n",
       "                                     test set scores  \\\n",
       "0  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "1  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "2  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "3  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "4  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "\n",
       "                                             comment target group  ...  \\\n",
       "0                                               None      Italian  ...   \n",
       "1  <p>a sentence initial language token is requir...     Romanian  ...   \n",
       "2                                               None      English  ...   \n",
       "3  <p>a sentence initial language token is requir...     Romanian  ...   \n",
       "4                                               None     Japanese  ...   \n",
       "\n",
       "  target languages  source language(s)  \\\n",
       "0              ita                None   \n",
       "1          mol ron                None   \n",
       "2              eng                None   \n",
       "3          mol ron                None   \n",
       "4              jpn                None   \n",
       "\n",
       "                           download original weights  \\\n",
       "0  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "1  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "2  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "3  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "4  https://object.pouta.csc.fi/Tatoeba-MT-models/...   \n",
       "\n",
       "                       scores              model dataset target language name  \\\n",
       "0  [BLEU: 54.8, chr-F: 0.737]  transformer-align    None                 None   \n",
       "1  [BLEU: 42.0, chr-F: 0.636]  transformer-align    None                 None   \n",
       "2  [BLEU: 27.1, chr-F: 0.550]  transformer-align    None                 None   \n",
       "3  [BLEU: 33.5, chr-F: 0.610]  transformer-align    None                 None   \n",
       "4  [BLEU: 15.2, chr-F: 0.258]  transformer-align    None                 None   \n",
       "\n",
       "  target language(s) source languages raw source language(s)  \n",
       "0               None              fra                    fra  \n",
       "1               None              deu                    deu  \n",
       "2               None              fin                   None  \n",
       "3               None              eng                   None  \n",
       "4               None              eng                   None  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединение схожих столбцов\n",
    "def get_frame(data, columns):\n",
    "    template = dict.fromkeys(columns) \n",
    "    result = []\n",
    "    for item in data:\n",
    "        tmp = template.copy()\n",
    "        for key, value in item.items():            \n",
    "            if key in tmp:\n",
    "                if key == 'source language(s)' or key == 'source language codes':\n",
    "                    key = 'source languages'\n",
    "                if key == 'target language(s)' or key == 'target language codes':\n",
    "                    key = 'target languages'\n",
    "                if key == 'source language name':\n",
    "                    key = 'source group'\n",
    "                if key == 'target language name':\n",
    "                    key = 'target group'\n",
    "                tmp[key] = value                \n",
    "        result.append(tmp)\n",
    "    return pd.DataFrame.from_dict(result)\n",
    "    \n",
    "\n",
    "get_frame(data, columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6f71631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение в таблицу table.xlsx\n",
    "sotr_columns = ['date', 'source languages', 'target languages', \n",
    "                'source group', 'target group', 'size (Mb)', \n",
    "                'scores', 'model',                \n",
    "                'download original weights', 'test set translations',\n",
    "                'OPUS readme', 'pre-processing', 'comment'\n",
    "                # 'dataset', # неинформативен\n",
    "                # 'test set scores', # дублирование\n",
    "               ]\n",
    "\n",
    "df = get_frame(data, columns)\n",
    "file = 'table.xlsx'\n",
    "with pd.ExcelWriter(file) as writer:\n",
    "    df.to_excel(writer, sheet_name=\"Модели\", columns=sotr_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255169b3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f069c29",
   "metadata": {},
   "source": [
    "# Структура моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96869a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = 'table.xlsx'\n",
    "df = pd.read_excel(file, index_col=0)\n",
    "source, target = df['source languages'], df['target languages']\n",
    "s, t = source.to_list(), target.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a8a42",
   "metadata": {},
   "source": [
    "## Всего доступно языковых пар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6002026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(s), len(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263d295",
   "metadata": {},
   "source": [
    "## Уникальных языковых пар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1949dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1330"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = [(i, j) for i, j in zip(s, t)]\n",
    "uniq = set(languages)\n",
    "len(uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843f31e",
   "metadata": {},
   "source": [
    "## Повторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c075bc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = [(i, j) for i, j in zip(s, t)]\n",
    "len(set([k for k in languages if languages.count(k) > 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9beb0",
   "metadata": {},
   "source": [
    "## Симметричные пары"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d45a9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both = []\n",
    "for i in range(len(s)):\n",
    "    for j in range(len(s)):\n",
    "        if len(s[i]) <= 5 and len(t[i]) <= 5:\n",
    "            if s[i] == t[j] and t[i] == s[j] and\\\n",
    "            s[i] != t[i] and s[j] != t[j] and\\\n",
    "            (s[i], t[i]) not in both:\n",
    "                both.append((s[i], t[i]))\n",
    "len(both)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22dfb98",
   "metadata": {},
   "source": [
    "## Число языков симметричных пар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e82488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two = []\n",
    "for i in range(len(s)):\n",
    "    for j in range(len(s)):\n",
    "        if len(s[i]) <= 5 and len(t[i]) <= 5:\n",
    "            if s[i] == t[j] and t[i] == s[j] and\\\n",
    "            s[i] != t[i] and s[j] != t[j] and\\\n",
    "            (t[i], s[i]) not in two and\\\n",
    "            (s[i], t[i]) not in two:\n",
    "                two.append((s[i], t[i]))\n",
    "len(two)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee963db7",
   "metadata": {},
   "source": [
    "## Ассиметричные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a880bb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_set = set(both)\n",
    "one = []\n",
    "for i in range(len(s)):\n",
    "    for j in range(len(s)):\n",
    "        if len(s[i]) <= 5 and len(t[i]) <= 5 and (s[i], t[i]) not in both_set:\n",
    "            if (s[i], t[i]) not in one and (t[i], s[i]) not in one and\\\n",
    "            ((s[i] == t[j] and t[i] != s[j]) or (s[i] != t[j] and t[i] == s[j])):\n",
    "                one.append((s[i], t[i]))\n",
    "len(one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac456a",
   "metadata": {},
   "source": [
    "## Комбинации языков (длина названия языков больше 5 символов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "376bec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long = set()\n",
    "for i in range(len(s)):\n",
    "    for j in range(len(s)):\n",
    "        if len(s[i]) > 5 or len(t[i]) > 5:\n",
    "            long.add((s[i], t[i]))\n",
    "len(long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf690a8",
   "metadata": {},
   "source": [
    "## Однородные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71f2a652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat = set()\n",
    "for i in range(len(s)):\n",
    "    if len(s[i]) <= 5 and len(t[i]) <= 5 and s[i] == t[i]:\n",
    "        repeat.add((s[i], t[i]))\n",
    "len(repeat)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
